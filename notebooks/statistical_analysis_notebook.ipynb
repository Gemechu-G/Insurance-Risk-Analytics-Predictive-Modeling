{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9739c202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats # You'll need this for statistical tests\n",
    "import numpy as np\n",
    "\n",
    "# Load your data (adjust path if using processed_insurance_v1.csv)\n",
    "df = pd.read_csv(\n",
    "    \"../data/insurance.csv\",\n",
    "    parse_dates=['TransactionMonth'], # Ensure this column name is correct from Task 1 fix\n",
    "    dtype={'PostalCode': 'str'}\n",
    ")\n",
    "\n",
    "# Convert TransactionMonth to datetime if not already done\n",
    "df['TransactionMonth'] = pd.to_datetime(df['TransactionMonth'])\n",
    "\n",
    "# Ensure numerical columns are correctly typed\n",
    "numeric_cols = ['TotalPremium', 'TotalClaims', 'CustomValueEstimate', 'CalculatedPremiumPerTerm', 'SumInsured']\n",
    "for col in numeric_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021ced95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['has_claim'] = (df['TotalClaims'] > 0).astype(int)\n",
    "df['claim_amount_if_claimed'] = df['TotalClaims'].where(df['has_claim'] == 1)\n",
    "df['margin'] = df['TotalPremium'] - df['TotalClaims']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761b0a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a contingency table for 'Province' and 'has_claim'\n",
    "contingency_table_province_claim = pd.crosstab(df['Province'], df['has_claim'])\n",
    "print(\"\\nContingency Table (Province vs. Has Claim):\\n\", contingency_table_province_claim)\n",
    "\n",
    "# Perform Chi-squared test\n",
    "chi2_freq_province, p_freq_province, _, _ = stats.chi2_contingency(contingency_table_province_claim)\n",
    "print(f\"\\nChi-squared test for Claim Frequency across Provinces:\")\n",
    "print(f\"Chi-squared statistic: {chi2_freq_province:.4f}\")\n",
    "print(f\"P-value: {p_freq_province:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5445c7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for policies with claims to calculate severity\n",
    "df_claimed = df[df['has_claim'] == 1].dropna(subset=['claim_amount_if_claimed'])\n",
    "\n",
    "# Create a list of claim amounts for each province\n",
    "province_groups = [df_claimed['claim_amount_if_claimed'][df_claimed['Province'] == p] for p in df_claimed['Province'].unique()]\n",
    "\n",
    "# Perform ANOVA test\n",
    "f_stat_severity_province, p_severity_province = stats.f_oneway(*province_groups)\n",
    "print(f\"\\nANOVA test for Claim Severity across Provinces:\")\n",
    "print(f\"F-statistic: {f_stat_severity_province:.4f}\")\n",
    "print(f\"P-value: {p_severity_province:.4f}\")\n",
    "\n",
    "# Optional: If p_severity_province < 0.05, consider post-hoc tests (e.g., Tukey HSD)\n",
    "# from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "# tukey_results = pairwise_tukeyhsd(endog=df_claimed['claim_amount_if_claimed'], groups=df_claimed['Province'], alpha=0.05)\n",
    "# print(\"\\nTukey's HSD Post-Hoc Test for Claim Severity:\\n\", tukey_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd77eb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify top/bottom zipcodes by claim frequency or severity from EDA\n",
    "# Example: Let's take top 5 and bottom 5 zipcodes by total claims for simplicity\n",
    "top_n_zipcodes = df.groupby('PostalCode')['TotalClaims'].sum().nlargest(5).index\n",
    "bottom_n_zipcodes = df.groupby('PostalCode')['TotalClaims'].sum().nsmallest(5).index # Exclude 0 claim zipcodes if many\n",
    "\n",
    "# Filter data for selected zipcodes for testing\n",
    "df_selected_zipcodes = df[df['PostalCode'].isin(list(top_n_zipcodes) + list(bottom_n_zipcodes))]\n",
    "\n",
    "# Perform Chi-squared for Claim Frequency\n",
    "contingency_table_zip_claim = pd.crosstab(df_selected_zipcodes['PostalCode'], df_selected_zipcodes['has_claim'])\n",
    "chi2_freq_zip, p_freq_zip, _, _ = stats.chi2_contingency(contingency_table_zip_claim)\n",
    "print(f\"\\nChi-squared test for Claim Frequency across selected Zipcodes:\")\n",
    "print(f\"Chi-squared statistic: {chi2_freq_zip:.4f}\")\n",
    "print(f\"P-value: {p_freq_zip:.4f}\")\n",
    "\n",
    "# Perform ANOVA for Claim Severity\n",
    "df_claimed_zip = df_selected_zipcodes[df_selected_zipcodes['has_claim'] == 1].dropna(subset=['claim_amount_if_claimed'])\n",
    "zip_groups_severity = [df_claimed_zip['claim_amount_if_claimed'][df_claimed_zip['PostalCode'] == z] for z in df_claimed_zip['PostalCode'].unique()]\n",
    "f_stat_severity_zip, p_severity_zip = stats.f_oneway(*zip_groups_severity)\n",
    "print(f\"\\nANOVA test for Claim Severity across selected Zipcodes:\")\n",
    "print(f\"F-statistic: {f_stat_severity_zip:.4f}\")\n",
    "print(f\"P-value: {p_severity_zip:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9c7ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same selected zipcodes as in Hypothesis 2, or broaden if data allows\n",
    "# Group margin data by PostalCode\n",
    "zip_groups_margin = [df_selected_zipcodes['margin'][df_selected_zipcodes['PostalCode'] == z] for z in df_selected_zipcodes['PostalCode'].unique()]\n",
    "\n",
    "# Perform ANOVA test for Margin\n",
    "f_stat_margin_zip, p_margin_zip = stats.f_oneway(*zip_groups_margin)\n",
    "print(f\"\\nANOVA test for Margin across selected Zipcodes:\")\n",
    "print(f\"F-statistic: {f_stat_margin_zip:.4f}\")\n",
    "print(f\"P-value: {p_margin_zip:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9d38fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize gender values\n",
    "df['Gender'] = df['Gender'].replace({'F': 'Female', 'M': 'Male', 'Woman': 'Female', 'Man': 'Male'})\n",
    "df_gender_clean = df[df['Gender'].isin(['Female', 'Male'])] # Filter for only valid genders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e236d931",
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table_gender_claim = pd.crosstab(df_gender_clean['Gender'], df_gender_clean['has_claim'])\n",
    "print(\"\\nContingency Table (Gender vs. Has Claim):\\n\", contingency_table_gender_claim)\n",
    "\n",
    "chi2_freq_gender, p_freq_gender, _, _ = stats.chi2_contingency(contingency_table_gender_claim)\n",
    "print(f\"\\nChi-squared test for Claim Frequency between Genders:\")\n",
    "print(f\"Chi-squared statistic: {chi2_freq_gender:.4f}\")\n",
    "print(f\"P-value: {p_freq_gender:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff9d243",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_claimed_gender = df_gender_clean[df_gender_clean['has_claim'] == 1].dropna(subset=['claim_amount_if_claimed'])\n",
    "women_claims = df_claimed_gender['claim_amount_if_claimed'][df_claimed_gender['Gender'] == 'Female']\n",
    "men_claims = df_claimed_gender['claim_amount_if_claimed'][df_claimed_gender['Gender'] == 'Male']\n",
    "\n",
    "# Perform Independent Samples t-test\n",
    "t_stat_severity_gender, p_severity_gender = stats.ttest_ind(women_claims, men_claims, equal_var=False) # Welch's t-test if variances are unequal\n",
    "print(f\"\\nT-test for Claim Severity between Genders:\")\n",
    "print(f\"T-statistic: {t_stat_severity_gender:.4f}\")\n",
    "print(f\"P-value: {p_severity_gender:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
