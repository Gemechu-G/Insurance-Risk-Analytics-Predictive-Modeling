{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfa62ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lr_severity = Pipeline(steps=[('preprocessor', preprocessor_severity),\n",
    "                                    ('regressor', LinearRegression())])\n",
    "pipeline_lr_severity.fit(X_train_severity, y_train_severity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b396b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_rf_severity = Pipeline(steps=[('preprocessor', preprocessor_severity),\n",
    "                                    ('regressor', RandomForestRegressor(random_state=42, n_jobs=-1))])\n",
    "pipeline_rf_severity.fit(X_train_severity, y_train_severity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29c7674",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_xgb_severity = Pipeline(steps=[('preprocessor', preprocessor_severity),\n",
    "                                     ('regressor', xgb.XGBRegressor(objective='reg:squarederror', random_state=42, n_jobs=-1))])\n",
    "pipeline_xgb_severity.fit(X_train_severity, y_train_severity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91496f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lr_prob = Pipeline(steps=[('preprocessor', preprocessor_prob),\n",
    "                                ('classifier', LogisticRegression(random_state=42, solver='liblinear'))])\n",
    "pipeline_lr_prob.fit(X_train_prob, y_train_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aea697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_rf_prob = Pipeline(steps=[('preprocessor', preprocessor_prob),\n",
    "                                ('classifier', RandomForestClassifier(random_state=42, n_jobs=-1))])\n",
    "pipeline_rf_prob.fit(X_train_prob, y_train_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293cefbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_xgb_prob = Pipeline(steps=[('preprocessor', preprocessor_prob),\n",
    "                                 ('classifier', xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss', random_state=42, n_jobs=-1))])\n",
    "pipeline_xgb_prob.fit(X_train_prob, y_train_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c30faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_severity = {\n",
    "    \"Linear Regression\": pipeline_lr_severity,\n",
    "    \"Random Forest Regressor\": pipeline_rf_severity,\n",
    "    \"XGBoost Regressor\": pipeline_xgb_severity\n",
    "}\n",
    "\n",
    "results_severity = {}\n",
    "for name, model in models_severity.items():\n",
    "    y_pred = model.predict(X_test_severity)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_severity, y_pred))\n",
    "    r2 = r2_score(y_test_severity, y_pred)\n",
    "    results_severity[name] = {'RMSE': rmse, 'R2': r2}\n",
    "    print(f\"{name} - RMSE: {rmse:.2f}, R2: {r2:.2f}\")\n",
    "\n",
    "# You can then convert results_severity to a DataFrame for a nice comparison table\n",
    "# pd.DataFrame(results_severity).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c548dfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_prob = {\n",
    "    \"Logistic Regression\": pipeline_lr_prob,\n",
    "    \"Random Forest Classifier\": pipeline_rf_prob,\n",
    "    \"XGBoost Classifier\": pipeline_xgb_prob\n",
    "}\n",
    "\n",
    "results_prob = {}\n",
    "for name, model in models_prob.items():\n",
    "    y_pred = model.predict(X_test_prob)\n",
    "    y_pred_proba = model.predict_proba(X_test_prob)[:, 1] # Probability of positive class\n",
    "\n",
    "    accuracy = accuracy_score(y_test_prob, y_pred)\n",
    "    precision = precision_score(y_test_prob, y_pred)\n",
    "    recall = recall_score(y_test_prob, y_pred)\n",
    "    f1 = f1_score(y_test_prob, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test_prob, y_pred_proba)\n",
    "\n",
    "    results_prob[name] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'ROC-AUC': roc_auc\n",
    "    }\n",
    "    print(f\"\\n{name} - Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1-Score: {f1:.2f}, ROC-AUC: {roc_auc:.2f}\")\n",
    "\n",
    "# pd.DataFrame(results_prob).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dc5997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- For the best severity model (e.g., XGBoost Regressor) ---\n",
    "best_severity_model = models_severity[\"XGBoost Regressor\"].named_steps['regressor']\n",
    "# Transform data using the preprocessor used in the pipeline\n",
    "X_train_severity_transformed = models_severity[\"XGBoost Regressor\"].named_steps['preprocessor'].fit_transform(X_train_severity)\n",
    "X_test_severity_transformed = models_severity[\"XGBoost Regressor\"].named_steps['preprocessor'].transform(X_test_severity)\n",
    "\n",
    "# Get feature names after one-hot encoding\n",
    "ohe_feature_names = models_severity[\"XGBoost Regressor\"].named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(severity_categorical_features)\n",
    "all_feature_names_severity = severity_numerical_features + ohe_feature_names.tolist()\n",
    "\n",
    "# Create a DataFrame for transformed data with proper column names\n",
    "X_train_severity_transformed_df = pd.DataFrame(X_train_severity_transformed, columns=all_feature_names_severity)\n",
    "X_test_severity_transformed_df = pd.DataFrame(X_test_severity_transformed, columns=all_feature_names_severity)\n",
    "\n",
    "\n",
    "explainer_severity = shap.TreeExplainer(best_severity_model)\n",
    "shap_values_severity = explainer_severity.shap_values(X_test_severity_transformed_df)\n",
    "\n",
    "# Plot global feature importances (SHAP summary plot)\n",
    "shap.summary_plot(shap_values_severity, X_test_severity_transformed_df, plot_type=\"bar\", show=False)\n",
    "plt.title(\"SHAP Feature Importance for Claim Severity Prediction\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../notebook/severity_shap_summary_bar.png\") # Save plot\n",
    "plt.show()\n",
    "\n",
    "shap.summary_plot(shap_values_severity, X_test_severity_transformed_df, show=False) # For individual impacts\n",
    "plt.title(\"SHAP Feature Impacts for Claim Severity Prediction\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../notebook/severity_shap_summary_dot.png\") # Save plot\n",
    "plt.show()\n",
    "\n",
    "# --- Repeat for the best probability model (e.g., XGBoost Classifier) ---\n",
    "best_prob_model = models_prob[\"XGBoost Classifier\"].named_steps['classifier']\n",
    "X_train_prob_transformed = models_prob[\"XGBoost Classifier\"].named_steps['preprocessor'].fit_transform(X_train_prob)\n",
    "X_test_prob_transformed = models_prob[\"XGBoost Classifier\"].named_steps['preprocessor'].transform(X_test_prob)\n",
    "\n",
    "ohe_feature_names_prob = models_prob[\"XGBoost Classifier\"].named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(prob_categorical_features)\n",
    "all_feature_names_prob = prob_numerical_features + ohe_feature_names_prob.tolist()\n",
    "\n",
    "X_train_prob_transformed_df = pd.DataFrame(X_train_prob_transformed, columns=all_feature_names_prob)\n",
    "X_test_prob_transformed_df = pd.DataFrame(X_test_prob_transformed, columns=all_feature_names_prob)\n",
    "\n",
    "\n",
    "explainer_prob = shap.TreeExplainer(best_prob_model)\n",
    "# For classification, shap_values might return an array for each class; take the one for the positive class (index 1)\n",
    "shap_values_prob = explainer_prob.shap_values(X_test_prob_transformed_df)[1] # Take SHAP values for class 1\n",
    "\n",
    "shap.summary_plot(shap_values_prob, X_test_prob_transformed_df, plot_type=\"bar\", show=False)\n",
    "plt.title(\"SHAP Feature Importance for Claim Probability Prediction\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../notebook/prob_shap_summary_bar.png\") # Save plot\n",
    "plt.show()\n",
    "\n",
    "shap.summary_plot(shap_values_prob, X_test_prob_transformed_df, show=False)\n",
    "plt.title(\"SHAP Feature Impacts for Claim Probability Prediction\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../notebook/prob_shap_summary_dot.png\") # Save plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
